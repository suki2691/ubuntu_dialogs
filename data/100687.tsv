2012-08-31T04:41:00.000Z	djabbour		Hi all. I've got a LVM volume (called vg0 / public) that is built on top of two md raid arrays. I'm currently in the process of adding a third array, and pvmoving one of the (old and degraded) arrays out. md0, md1 are old, and md2 is new. md0, however, booted with one failed disk. Now, md is reporting two failed drives, and device-mapper is reporting "raid1: Unable to read primary mirror during recovery". I'm in the process of pvmovi
2012-08-31T04:41:00.000Z	djabbour		ng away from this broken array. The vol group appears to be still operational, despite md0 showing two failed drives now in mdstat. (1) How is this possible? I thought once two drives fail inraid5, the volume shouldn't be readable? and (2) pvmove is running VERY slow. Looks like it's going to take another 3-4 days at this rate. Is there anything I can do to speed up this process or prevent futher data loss?
2012-08-31T04:42:00.000Z	graingert	djabbour	yes, slow down time
2012-08-31T04:42:00.000Z	graingert	djabbour	(I think this channel is too noobish for your requirements - you seem fairly expert) perhaps ask in the dm raid irc?
